{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f59459e",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning\n",
    "\n",
    "<img src=\"https://lamarr-institute.org/wp-content/uploads/deepLearn_2_EN-2048x1024.png\" style=\"width: 800px; background: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e7122",
   "metadata": {},
   "source": [
    "Deep learning is a field of artificial intelligence that teaches computers to learn from examples. It is inspired by the way the human brain works. In deep learning, we use neural networks, which are systems made of layers of connected nodes called “neurons.”\n",
    "\n",
    "These networks learn by looking at many examples. For example, if we want a computer to recognize cats, we show it thousands of cat pictures. Over time, the network learns what features make a cat: shapes, colors, and patterns.\n",
    "\n",
    "Deep learning is powerful because it can find complex patterns that are hard for humans to describe. It is used in many areas, such as voice assistants, self-driving cars, medical image analysis, and translation tools.\n",
    "\n",
    "Although deep learning can achieve impressive results, it needs large amounts of data and strong computers to train the models. It can also be difficult to understand how the model makes decisions, since the learning happens inside many layers.\n",
    "\n",
    "In summary, deep learning is a modern approach that allows computers to learn from data in a way that is flexible and effective, making it an important technology in today’s world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba0eaa",
   "metadata": {},
   "source": [
    "<img src=\"https://towardsdatascience.com/wp-content/uploads/2021/12/1hkYlTODpjJgo32DoCOWN5w.png\" style=\"width: 800px\">\n",
    "\n",
    "<br>\n",
    "<img src=\"https://nickmccullum.com/images/python-deep-learning/understanding-neurons-deep-learning/activation-function.png\" style=\"width: 800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0693796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after first hidden layer: [5.5, 3.5, 7.0]\n",
      "Output after second hidden layer: [6.25, 3.35]\n",
      "Final output of the network: [8.305]\n",
      "Activated final output (ReLU): [8.305]\n"
     ]
    }
   ],
   "source": [
    "# The features from the input layer\n",
    "input_layer = [1, 2, 3, 4, 5]\n",
    "\n",
    "# The weights for the connections between layers\n",
    "hidden_layer1 = [\n",
    "    [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "    [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "]\n",
    "hidden_layer2 = [\n",
    "    [0.5, 0.4, 0.3],\n",
    "    [0.1, 0.2, 0.3]\n",
    "]\n",
    "output_layer = [\n",
    "    [0.9, 0.8]\n",
    "]\n",
    "\n",
    "\n",
    "# Function to perform matrix multiplication\n",
    "def matrix_multiply(inputs, weights):\n",
    "    outputs = []\n",
    "    for weight_vector in weights:\n",
    "        output = sum(i * w for i, w in zip(inputs, weight_vector))\n",
    "        outputs.append(output)\n",
    "    return outputs\n",
    "\n",
    "# Forward pass through the network\n",
    "hidden_output1 = matrix_multiply(input_layer, hidden_layer1)\n",
    "print(\"Output after first hidden layer:\", hidden_output1)\n",
    "\n",
    "hidden_output2 = matrix_multiply(hidden_output1, hidden_layer2)\n",
    "print(\"Output after second hidden layer:\", hidden_output2)\n",
    "\n",
    "final_output = matrix_multiply(hidden_output2, output_layer)\n",
    "print(\"Final output of the network:\", final_output)\n",
    "\n",
    "# activation function\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "# Applying ReLU activation function to final output\n",
    "activated_output = [relu(x) for x in final_output]\n",
    "\n",
    "print(\"Activated final output (ReLU):\", activated_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d036db63",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*EZiBCBstS5malFC38HGKig.jpeg\" style=\"width: 800px\">\n",
    "<br>\n",
    "<img src=\"https://mukulrathi.com/static/b4793bf4ff6f9063ff9a3d00f1ebf6ec/e629e/grad-descent.webp\" style=\"width: 800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc4a92",
   "metadata": {},
   "source": [
    "Training a deep learning model means teaching the model to make good predictions by learning from data. The process starts with many examples, such as images, sentences, or numbers. Each example has an input and often a correct answer, called a label.\n",
    "\n",
    "The model makes a prediction, and then we compare this prediction with the correct answer. The difference between them is called the loss. A high loss means the model is wrong, and a low loss means the model is learning well.\n",
    "\n",
    "To improve, the model adjusts its internal values, called weights. This is done using an algorithm called backpropagation, which calculates how much each weight should change. Another algorithm, called an optimizer (like SGD or Adam), updates the weights step by step.\n",
    "\n",
    "This process repeats many times over the entire dataset. With each pass, the model becomes a little better at recognizing patterns. After enough training, the model can make accurate predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb7097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 5.305\n",
      "Old prediction: 8.305\n",
      "New prediction after weight update: [5.479291101463751]\n"
     ]
    }
   ],
   "source": [
    "# calculating the loss\n",
    "\n",
    "target = 3.0\n",
    "prediction = activated_output[0]\n",
    "\n",
    "loss = prediction - target\n",
    "print(\"\\nLoss:\", loss)\n",
    "\n",
    "\n",
    "# SUPER-SIMPLE BACKPROP (educational only)\n",
    "# Each weight is updated using:\n",
    "# new_weight = old_weight - lr * loss\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "def update_weights(layer):\n",
    "    for i in range(len(layer)):\n",
    "        for j in range(len(layer[i])):\n",
    "            layer[i][j] -= learning_rate * loss\n",
    "\n",
    "update_weights(output_layer)\n",
    "update_weights(hidden_layer2)\n",
    "update_weights(hidden_layer1)\n",
    "\n",
    "\n",
    "# Forward pass again after weight update\n",
    "hidden_output1_new = matrix_multiply(input_layer, hidden_layer1)\n",
    "hidden_output2_new = matrix_multiply(hidden_output1_new, hidden_layer2)\n",
    "final_output_new = matrix_multiply(hidden_output2_new, output_layer)\n",
    "activated_output = [relu(x) for x in final_output_new]\n",
    "\n",
    "print(\"Old prediction:\", prediction)\n",
    "print(\"New prediction after weight update:\", activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20541213",
   "metadata": {},
   "source": [
    "Tensor Flow, from google, has a cool playground we can use to understand how all this process works!\n",
    "\n",
    "https://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8cf25e",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0df75",
   "metadata": {},
   "source": [
    "PyTorch is an open-source library used to build and train deep learning models. It is widely used in research and industry because it is easy to learn and flexible.\n",
    "\n",
    "PyTorch works with tensors, which are similar to arrays or matrices. Tensors can run on the CPU or on the GPU, making computations faster when working with large models.\n",
    "\n",
    "https://pytorch.org/\n",
    "\n",
    "https://developer.nvidia.com/cuda/toolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3078df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 14 21:04:41 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 37%   41C    P8             N/A /  115W |     429MiB /   8188MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      7804    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac49b2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu126\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d1578",
   "metadata": {},
   "source": [
    "Recreating the simple newral net from previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f6019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 3)\n",
    "        self.fc2 = nn.Linear(3, 2)\n",
    "        self.fc3 = nn.Linear(2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d99df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1721], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model = SimpleNN()\n",
    "prediction = model(torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0]))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27fce33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 10.062329292297363\n",
      "Epoch 2/10, Loss: 5.28465461730957\n",
      "Epoch 3/10, Loss: 3.38217830657959\n",
      "Epoch 4/10, Loss: 2.1645941734313965\n",
      "Epoch 5/10, Loss: 1.3853403329849243\n",
      "Epoch 6/10, Loss: 0.88661789894104\n",
      "Epoch 7/10, Loss: 0.5674353241920471\n",
      "Epoch 8/10, Loss: 0.3631584942340851\n",
      "Epoch 9/10, Loss: 0.23242133855819702\n",
      "Epoch 10/10, Loss: 0.14874958992004395\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inputs = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "    target = torch.tensor([3.0])\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51a088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6915], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prediction = model(torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0]))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794eb32c",
   "metadata": {},
   "source": [
    "# Text generation with deep learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f3203",
   "metadata": {},
   "source": [
    "For this example, we are going to use recurrent newral networks!\n",
    "\n",
    "We will use a dataset from Shakespeare to create a newral network able to write text!\n",
    "\n",
    "https://www.kaggle.com/datasets/kingburrito666/shakespeare-plays?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0864b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataline</th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
       "0         1  Henry IV               NaN          NaN            NaN   \n",
       "1         2  Henry IV               NaN          NaN            NaN   \n",
       "2         3  Henry IV               NaN          NaN            NaN   \n",
       "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
       "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
       "\n",
       "                                          PlayerLine  \n",
       "0                                              ACT I  \n",
       "1                       SCENE I. London. The palace.  \n",
       "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "3             So shaken as we are, so wan with care,  \n",
       "4         Find we a time for frighted peace to pant,  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/Shakespeare_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e275f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training lines: 89116\n",
      "Number of validation lines: 22280\n"
     ]
    }
   ],
   "source": [
    "lines = df['PlayerLine'].dropna().astype(str).tolist()\n",
    "\n",
    "cutoff_index = int(0.8 * len(lines))\n",
    "train_lines, val_lines = lines[:cutoff_index], lines[cutoff_index:]\n",
    "\n",
    "print(f\"Number of training lines: {len(train_lines)}\")\n",
    "print(f\"Number of validation lines: {len(val_lines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee66ae",
   "metadata": {},
   "source": [
    "**Extracting the tokens!**\n",
    "\n",
    "We have our phrases, but AI doesn't work with frases, we need numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c09bcf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First frase: So shaken as we are, so wan with care,\n",
      "Tokens in the first phrase: ['So', 'shaken', 'as', 'we', 'are', 'so', 'wan', 'with', 'care']\n",
      "\n",
      "Vocabulary size: 20574\n",
      "\n",
      "First 20 tokens: ['10' '2d' '2s' '4d' '5s' '6d' '8d' 'abaissiez' 'abandon' 'abandoned'\n",
      " 'abase' 'abate' 'abated' 'abatement' 'abatements' 'abbess' 'abbey'\n",
      " 'abbeys' 'abbominable' 'abbot']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_lines)\n",
    "\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "tokens = tokenizer(train_lines[3])\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"\"\"\n",
    "First frase: {train_lines[3]}\n",
    "Tokens in the first phrase: {tokens}\n",
    "\n",
    "Vocabulary size: {len(vocab)}\n",
    "\n",
    "First 20 tokens: {vocab[:20]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e1f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(vocab)\n",
    "vocab.append('<EOF>') # END OF FILE token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018176db",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {word: idx for idx, word in enumerate(vocab)}\n",
    "index2word = {idx: word for word, idx in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2361f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase: To be, or not to be, that is the question.\n",
      "Tokens: ['To', 'be', 'or', 'not', 'to', 'be', 'that', 'is', 'the', 'question']\n",
      "Indices: [1378, 12301, 12029, 18177, 1378, 17910, 9653, 17916, 14255]\n",
      "Words from indices: ['be', 'or', 'not', 'to', 'be', 'that', 'is', 'the', 'question']\n"
     ]
    }
   ],
   "source": [
    "phrase = \"To be, or not to be, that is the question.\"\n",
    "tokens = tokenizer(phrase)\n",
    "indices = [word2index[token] for token in tokens if token in word2index]\n",
    "words = [index2word[idx] for idx in indices]\n",
    "\n",
    "print(f\"Phrase: {phrase}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Indices: {indices}\")\n",
    "print(f\"Words from indices: {words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b148f",
   "metadata": {},
   "source": [
    "**Embbedings**\n",
    "\n",
    "Embeddings are ways to represent our frases a matrix of float numbers. It is important when working with AI, in special for nlp (natural language processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input indices: [1378, 12301, 12029, 18177, 1378, 17910, 9653, 17916, 14255]\n",
      "Embedded output:\n",
      "tensor([[-1.1392e+00,  7.2054e-02,  7.7972e-04, -1.4003e-01,  9.1053e-01],\n",
      "        [-1.7629e-01,  1.3517e+00, -6.8322e-01, -1.0474e+00, -4.3596e-01],\n",
      "        [-2.5106e-01, -1.1762e+00,  2.0946e-01,  4.6188e-01,  5.4676e-01],\n",
      "        [ 1.1102e+00, -5.8836e-01, -2.8079e-03, -1.0986e-01,  2.9528e-01],\n",
      "        [-1.1392e+00,  7.2054e-02,  7.7972e-04, -1.4003e-01,  9.1053e-01],\n",
      "        [-4.9812e-01, -5.7807e-02,  3.2006e-01, -1.8862e-02, -1.5732e-02],\n",
      "        [-9.3847e-01,  2.0246e-01,  2.4391e-01, -1.8471e-01,  8.6820e-01],\n",
      "        [-1.6026e+00,  1.9846e-01,  1.0945e-01,  1.7788e+00, -7.6462e-01],\n",
      "        [-4.3056e-01, -7.3652e-01, -1.1400e+00,  9.3324e-01,  2.8117e-01]])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "phrase = \"To be, or not to be, that is the question.\"\n",
    "\n",
    "tokens = tokenizer(phrase)\n",
    "indices = [word2index[token] for token in tokens if token in word2index]\n",
    "\n",
    "input_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "embedding_dim = 5\n",
    "embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embedding_dim)\n",
    "embedded_output = embedding_layer(input_tensor)\n",
    "\n",
    "print(f\"Input indices: {indices}\")\n",
    "print(\"Embedded output:\")\n",
    "print(embedded_output.detach().squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250dc34",
   "metadata": {},
   "source": [
    "**The Recurrent Newral Netword Model**\n",
    "\n",
    "Now we can create the model we are going to train\n",
    "\n",
    "<img src=\"https://mdpi-res.com/information/information-15-00517/article_deploy/html/images/information-15-00517-g001.png\" style=\"width: 500px;\">\n",
    "\n",
    "This model is going to be based on RRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN(\n",
      "  (embedding): Embedding(20575, 5)\n",
      "  (lstm): LSTM(5, 32, num_layers=3, batch_first=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=32, out_features=20575, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, hidden_layers=3, dropout_prob=0.2):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=hidden_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 5\n",
    "hidden_dim = 32\n",
    "\n",
    "\n",
    "model = SimpleRNN(vocab_size, embedding_dim, hidden_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29899bcf",
   "metadata": {},
   "source": [
    "**Training our model**\n",
    "\n",
    "Now that we know how to extract tokens, convert into embeddings and we also have our model, we can train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences prepared: 82828\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare input data\n",
    "\n",
    "sequences = []\n",
    "for line in train_lines:\n",
    "    tokens = tokenizer(line)\n",
    "    indices = [word2index[token] for token in tokens if token in word2index]\n",
    "    if len(indices) > 1:\n",
    "        sequences.append(indices)\n",
    "\n",
    "print(f\"Number of sequences prepared: {len(sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set hyperparameters\n",
    "\n",
    "embedding_dim = 5\n",
    "\n",
    "hidden_dim = 1024\n",
    "hidden_layers = 3\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 500\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/500, Loss: 0.2184\n",
      "Epoch 50/500, Loss: 0.0557\n",
      "Epoch 100/500, Loss: 0.0390\n",
      "Epoch 150/500, Loss: 0.0364\n",
      "Epoch 200/500, Loss: 0.0352\n",
      "Epoch 250/500, Loss: 0.0345\n",
      "Epoch 300/500, Loss: 0.0340\n",
      "Epoch 350/500, Loss: 0.0337\n",
      "Epoch 400/500, Loss: 0.0335\n",
      "Epoch 450/500, Loss: 0.0333\n",
      "Epoch 500/500, Loss: 0.0333\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the model\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = SimpleRNN(vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    random.shuffle(sequences)\n",
    "\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch = sequences[i:i+batch_size]\n",
    "        \n",
    "        input_batch = [torch.tensor(seq[:-1], dtype=torch.long) for seq in batch]\n",
    "        target_batch = [torch.tensor(seq[1:], dtype=torch.long) for seq in batch]\n",
    "        input_padded = pad_sequence(input_batch, batch_first=True, padding_value=0).to(device)\n",
    "        target_padded = pad_sequence(target_batch, batch_first=True, padding_value=0).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(input_padded) \n",
    "\n",
    "        loss = criterion(output.view(-1, vocab_size), target_padded.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(sequences):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277bc91",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be so to you to the king and is not so much as you have been the world to be so\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_text, tokenizer, word2index, index2word, max_len=20, device='cpu'):\n",
    "    model.eval()\n",
    "    tokens = tokenizer(start_text)\n",
    "    indices = [word2index[token] for token in tokens if token in word2index]\n",
    "    input_seq = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    generated = indices.copy()\n",
    "\n",
    "    hidden = None\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            next_token_logits = output[0, -1]\n",
    "            next_token = torch.argmax(next_token_logits).item()\n",
    "            if index2word[next_token] == '<EOF>':\n",
    "                break\n",
    "            generated.append(next_token)\n",
    "            input_seq = torch.tensor([generated], dtype=torch.long).to(device)\n",
    "            \n",
    "\n",
    "    words = [index2word[idx] for idx in generated]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "start_text = \"to be\"\n",
    "print(generate_text(model, start_text, tokenizer, word2index, index2word, max_len=20, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2a6fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And I am tied to be obedient,\n",
      "am tied to be obedient nay and ll say to me was that to my\n"
     ]
    }
   ],
   "source": [
    "start_text = val_lines[0]\n",
    "print(start_text)\n",
    "print(generate_text(model, start_text, tokenizer, word2index, index2word, max_len=10, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"models/simple_rnn_shakespeare.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (embedding): Embedding(20575, 10)\n",
       "  (lstm1): LSTM(10, 512, batch_first=True)\n",
       "  (lstm2): LSTM(512, 512, batch_first=True)\n",
       "  (lstm3): LSTM(512, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=20575, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleRNN(vocab_size, embedding_dim, hidden_dim)\n",
    "model.load_state_dict(torch.load(\"models/simple_rnn_shakespeare.pth\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1dbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b099974b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b93dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-training (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
